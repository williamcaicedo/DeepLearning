{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 100000000\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    name = f.namelist()[0]\n",
    "    data = tf.compat.as_str(f.read(name))\n",
    "  return data\n",
    "  \n",
    "text = read_data(filename)\n",
    "print('Data size %d' % len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999000 ons anarchists advocate social relations based upon voluntary as\n",
      "1000  anarchism originated as a term of abuse first used against earl\n"
     ]
    }
   ],
   "source": [
    "valid_size = 1000\n",
    "valid_text = text[:valid_size]\n",
    "train_text = text[valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected character: ï\n",
      "1 26 0 0\n",
      "a z  \n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(string.ascii_lowercase) + 1 # [a-z] + ' '\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "def char2id(char):\n",
    "  if char in string.ascii_lowercase:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  else:\n",
    "    return ' '\n",
    "\n",
    "print(char2id('a'), char2id('z'), char2id(' '), char2id('ï'))\n",
    "print(id2char(1), id2char(26), id2char(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ons anarchists advocate social relations based upon voluntary association of autonomous individuals m', 'r have discovered roger bacon has also been attributed with originating the search for the philosophe', 'ormer nike surface to air missile site that same year oil was discovered in prudhoe bay on the arctic', 'r high regard for personal honor for their clan loyalty and for their readiness to carry and use arms', 'this use of the term is much more common in europe characteristics dragon ball z is one of the most p', 'n centimetres of mifune s body other stories include demanding a stream be made to run in the opposit', ' soviets from berlin speer even confessed to hitler shortly before the dictator s suicide that he had', 'e culture of organs and worked with lindbergh in the mid one nine three zero s to create the perfusio', 'a combination of glaukos which can be translated as gleaming silvery and later as bluish green or gra', ' cit ii six six two seven two four contests both these statements the former he traces to a mistaken ', 'n nine nine births one eight eight eight deaths alternative education tax resisters teachers transcen', 'olman also began their careers in the labor party labor like parties of the broad centre in most coun', 'd cabinet states admitted to the union nebraska one eight six seven post presidency president andrew ', 'ans and the outlying islands were completely surveyed topographically by the indian survey department', 'r of africa which though flowing to the atlantic has its principal source in the far west and reverse', 'that is at first based on the teacher s or classmates perception of success habits are often tied to ', 'use of airways was necessary because it was the only way for aircraft to navigate with precision in i', 'say that he constructed the ark before going upon mount sinai to receive the second set of tablets th', 'nto powering research the output of all three can be enhanced by facilities or by special inhabitants', 'can be interpreted more technically but in simplest terms it means that it is the algorithm that deci', 'nts and release day events apple has generally chosen to stick with some loose user interface element', 'land ant colonies are sometimes described as superorganisms because they appear to operate as a singl', 'even two charles fourier french philosopher d one eight three seven one eight zero three james curtis', 'o attain more humane treatment for animals but also to include species other than human beings within', 'e pressure of the air in the room where the recording part is placed has to be considered thus if the', 'n from the national media and from presidential candidate john f kennedy despite this incident atlant', 'nition in fortresses here the positions for the magazine and ammunition stores are so chosen as to af', 'ortunately when the album s release date finally came it was not a day of celebration love and theft ', 'nd west bengal the first literary text in bangla is the seventh century charyapada the medieval ages ', 'oyment of troops outside of bulgaria and ratification of international treaties and agreements politi', 'it reacts forming a colorless bromoalkane for example reaction with ethylene will produce one two dib', 'ns of binomial distributions binomial pdf and normal approximation for n six and p zero five if n is ', 'long relied on bicycles the royal mail first started using bicycles in one eight eight zero bicycle d', 'awa vice president operations with niels jensen ole henriksen and mogens glad based in copenhagen phi', 'ele sindebele tswana setswana sesotho zulu isizulu xhosa isixhosa sepedi swazi siswati in west africa', ' higher organisms large parts of the dna do not serve any obvious purpose this so called junk dna may', 'ber two zero zero three bnp wins another seat this is worcestershire it s no wonder the british natio', 'ngland and the channel islands as well as national stations of bbc radio wales bbc radio cymru in wel', 'o select a location that contains other immature eagles than one with no eagle population bald eagles', 'in the united states during world war ii due to copper being needed for shell casings several pattern', 'y eight inch two zero three mm of armour survived hits from one five inch three eight one mm shells h', 'ember two zero zero three helsinki on the situation of the basque language in the autonomous communit', ' foundation for the ritual of metzitzah b peh is found in mishnah shabbat one nine two which lists me', 'ive external links bob knight s page at the lubbock avalanche journal website one nine four zero birt', ' practice and identity in the banda islands maluku antropologi indonesia five seven seven one eight z', ' or message this usually consists of the singing of hymns praise and worship music or psalms many chu', 'nd a long adagio to end the work in one seven seven two haydn completed his opus two zero set of six ', 'e contention in the problem of universals believe that properties are beings the redness of all apple', ' cheeses milk is curdled and drained with little other processing examples include cottage cheese rom', ' ivan d ivo gunduli poet science ru er bo kovi physicist and jesuit faust vran i philosopher thinker ', 'gnificant than in jersey and guernsey has maintained light industry as a higher proportion of its eco', ' at the top of this page completion opening of the channel tunnel by queen elizabeth ii and french pr', 'ty nine seven one united arab emirates nine seven two israel nine seven three bahrain nine seven four', 's in category theory glossary of category theory references ad mek ji herrlich horst category theory ', 'heir daughter dorothy not until one nine five nine did the team pass out of the family thanks in part', 'he safety normally provided by the type system pointers c makes extensive use of pointers a very simp', 'ranges vary the above figures are based on the code of federal regulations title two one part one thr', ' programs anti soviet operations in afghanistan in the mid one nine eight zero s though with the seri', 'ven zero three legend has it that the cross was erected over the kistvaen burial chamber of childe th', 't connecticut is the second most italian american state percentage wise after rhode island blacks and', 'one nine seven zero s because in winter the canal freezes before the lakes and then after the lakes f', 'd exploitation of diamonds and gold in the transvaal region of south africa in the one eight seven ze', 'use garbage collection lisp which introduced functional programming is especially notable for using g', ' in one nine nine five as a project of steve chamberlain a cygnus engineer who observed that windows ', 'g corncobs and their husks which was executed by giuseppe franzoni and employed in the small domed ve', 'rson shooters a combination of mouse and keyboard is a popular way to play first person shooter fps g', 'zero zero feet to five miles apart as was the case in one game in the one nine th century kendall bla', 'ent out of fashion due to the acceptance of true teaching and scholarly exegesis a position that is h', ' of the premier league he quit halfway through the season and was replaced on a caretaker basis by fo', 'e ruble created opportunities for his circle and other enterpreneurs to seize the former people s pro', 'e shown incorrect with available scientific evidence creation science has therefore been considered b', 'th the band dissolution crass all but retired from the public eye after becoming a particularly irrit', 'd order today dictionaries of languages with alphabetic and syllabic writing systems list words in al', 'ernational one eight submarine fiber optic cables linking denmark with norway sweden russia poland ge', 'mpany whereas a generally satisfied workforce sees less identification with the character of dilbert ', ' drugs confusion inability to orient oneself later signs lethargy decreased ability to perform simple', 'oth ugly and difficult to understand as he began to understand the physics and how the physicists wer', 'ab mukherjee indian politician one nine three six taku yamasaki japanese politician one nine three ei', 'uency high frequency busy signal four eight zero hz six two zero hz dial tone three five zero hz four', 'ochtermann jim dose richard gray chuck jones stephen hornback dirk jones james storey david demaret d', 'o two one nine zero three publ one nine one three p seven two zero on dark matter hot news for cold d', 'anry w westminster dragoons squadron also bears the title of a former dragoon regiment in canada the ', 'ne two six joe paterno american football coach one nine three five john g avildsen american film dire', 'itanium hp new owner of compaq announced that development for the alpha series would continue for a f', 'he druids of the iron age many of our popular ideas about the druids are based on the misunderstandin', 'l pen pals penpals are even possible for elementary school students something that is far more diffic', 'ne took effect in one nine five two which established the european coal and steel community between a', 't zero zero km of estonian territory the army dumped hundreds of thousands of tons of jet fuel into t', 'cholarly accuracy and scope with a readability intended to gain a wider audience and increased sales ', 'ity and resinous or negative electricity this was the two fluid theory of electricity which was to be', 'rceived or real homogenization leveling out collusion or even the decline of anything from morals to ', 'ic such as portrait of hans j ger and partly impressionistic rue lafayette in one eight nine two munc', 'ultaneous entry into the realm of the golden dragon if the crossing occurs at the greenwich or prime ', 'ainst king george iii that led to the american revolution as well as for his strong opposition to the', 'ession were considered during elizabeth s reign one possible line was that of margaret tudor henry vi', 'and the uniformity in design and products of humble stations nationwide the company still had difficu', 'enter in the east commandant eamon de valera commanded the three rd battalion at boland s bakery and ', 'renetic raucous this year s model one nine seven eight some of the more popular tracks include the br', 'rity through obscurity a popular relative security measurement is counting known unpatched security f', ' role the french played virtually none the french foreign minister complained that a separate peace b']\n",
      "['mutual aid and self governance while anarchism is most easily defined by what it is against anarchist', 'er s stone and the elixir of life that medicine which will remove all impurities and corruptibilities', 'c slope and in one nine six nine oil lease sales brought billions of dollars to the state statue in d', 's to settle disputes heathcote two zero zero three as clan warfare internecine feuding has been one o', 'popular sh nen anime anime features a wide variety of artistic styles which vary from artist to artis', 'te direction in order to get a better visual effect and having the roof of a house removed later to b', 'd disobeyed and indeed actively hindered hitler s scorched earth decree according to speer s autobiog', 'on pump which allowed living organs to exist outside of the body during surgery the advance is said t', 'ay and ps eye or sometimes face it is interesting to note that glaux owl is from the same root presum', ' interpretation of origen hom i in luc lipsius on the other hand accepts the statements of jerome smi', 'ndentalism this article is about the bird family for other uses see albatross disambiguation the alba', 'ntries draws criticism from both left and right critics from the left say labor has abandoned its tra', ' johnson johnson was an unsuccessful candidate for election to the united states senate in one eight ', 't under colonel hobday in one eight eight three one eight eight six and the surrounding seas were cha', 'es the direction of flow exhibited by the nile and congo an important branch however the benue comes ', ' self image emotions and cultural assumptions the student must be willing and able to challenge the v', 'instrument conditions the use of gps has changed this by allowing direct routing allowing aircraft to', 'he charge of carrying the ark and the rest of the holy implements was given to the family of kohath o', 's called specialists energy credits created by the economy are the currency of the game it can be use', 'ides the speedup not the number of processors you eventually reach a place where you can not parallel', 'ts in all of its releases and many similarities can be seen between the legacy mac os nine and the mo', 'le entity ants have colonized almost every landmass on earth and can constitute up to one five of the', 'ss mayor of chicago d one eight five nine one eight four eight randall thomas davidson archbishop of ', 'n the moral community by giving their basic interests for example the interest in avoiding suffering ', 'e instrument depends on the pressure or suction effect alone and this pressure or suction is measured', 'ta s political and business leaders fostered atlanta s image as the city too busy to hate in one nine', 'fford the best means of protection from an enemy s fire huge earth parapets cover these buildings whi', ' reached stores on september one one two zero zero one the same morning terrorists hijacked four dome', ' saw much activity in bangla literature by poets like alaol and chandidas bangla literature matured i', 'ical parties and elections more info bulgarian parliamentary election two zero zero five judicial bra', 'bromoethane when added to phenol a white precipitate two four six tribromophenol will form history br', ' large enough and the skew of the distribution is not too great then an excellent approximation provi', 'delivery fleets include three seven zero zero zero in the uk two five seven zero zero in germany and ', 'ilippe kahn led the company as it developed a series of well regarded software development tools thei', 'a ngumba cameroon kako cameroon basaa cameroon some are usually known in english without the class pr', 'y however contain unrecognized functional elements bioinformatics helps to bridge the gap between gen', 'onal party s on the move two two september two zero zero three this article argues that the mainstrea', 'lsh bbc radio scotland bbc radio nan gaidheal in scots gaelic bbc radio ulster and bbc radio foyle th', 's are powerful fliers and ride thermal convection currents to range far they have a long lifespan wit', 'ns were made in one nine four two but steel was used instead in one nine four three and recycled shel', 'had these shells performed to design coupled with the british accuracy of fire german losses would pr', 'ty of navarre reported in mercator butlleti five five speakers of a regional or minority language sho', 'etzitzah b peh as one of the four steps involved in the circumcision rite the chatam sofer observed t', 'ths basketball hall of fame american basketball players american basketball coaches college men s bas', 'zero winn phillip two zero zero one graves groves and gardens place and identity in central maluku in', 'urches believe that worship is important to usher in the presence of god for the rest of the service ', ' string quartets in which he deploys the polyphonic techniques he gathered from the previous era to p', 'es is something that is to deny that universals exist is the scholastic variant of nominalism relatio', 'manian ca neufch tel the model for american style cream cheese and fresh goats milk ch vre such chees', ' sport davor uker football player top scorer football world cup one nine nine eight zvonimir boban fo', 'onomy than jersey jersey s economy since the one nine eight zero s has been substantially more relian', 'resident fran ois mitterrand the british and french efforts which had been guided by laser surveying ', 'r qatar nine seven five bhutan nine seven six mongolia nine seven seven nepal nine seven eight unassi', ' in stanford encyclopedia of philosophy homepage of the categories mailing list with extensive list o', 't to feud between dorothy and her brother chuck to a new ownership group led by bill veeck who had pr', 'ple type of reference that records in effect the address or location of an object in memory pointers ', 'ree one and a small sample of state regulations whipped cream served atop hot chocolate in the uk cre', 'ious downsides noted earlier the ultimate worth of these operations is open to considerable debate an', 'he hunter the cross has its base in a socket stone resting on granite blocks over the chamber the who', 'd hispanics mostly puerto ricans are numerous in the urban areas of the state six six of its populati', 'freeze the canal thaws and remains unfrozen for the rest of the winter although it is illegal to atte', 'ero s and one eight eight zero s led to rapid change cape town was soon no longer the single dominant', 'garbage collection before this technique was commonly used safe programming languages must use garbag', ' nt and nine five used coff as their object file format and that gnu already included support for x e', 'estibule of the supreme court only the supreme court survived the fire of august two four one eight o', 'games the x axis of the mouse is used for looking left and right while the y axis is used for looking', 'anchard the mississippi choctaws at play the serious side of leisure the mississippi band of choctaw ', 'held by many who believe in binitarianism is that jesus was the word and thus god john one before his', 'ormer chelsea hero david webb who guided chelsea to an one one th place finish webb was replaced at t', 'operty and moved toward restructuring the largely state owned economy after obtaining power the vast ', 'by most who evaluate it to be religious rather than scientific because it stems from faith in the bib', 'tating thorn in the side of margaret thatcher s government following the falklands war questions in p', 'lphabetical or some analogous phonetic order words and characters in ideographic writing systems such', 'ermany the netherlands united kingdom faroe islands iceland and canada satellite earth stations six i', ' and consequently fewer dilbert comic strips are displayed as mementoes an office with no dilbert str', 'e cognitive functions attention only by tactile auditory or visual stimuli late signs stupor sleep wi', 're using mathematics he developed a coherent mathematical theory for what he found most importantly i', 'ight mccoy tyner american jazz pianist one nine three nine tom hayden american politician one nine fo', 'r four zero hz ringback us four four zero hz four eight zero hz the tone frequencies as defined by th', 'douglas r wood lee jackson robert prince lani minella jon st john robert m atkins michael hadwin exte', 'dark matter most of our universe is missing external links hot dark matter dark matter portal g berto', ' royal canadian mounted police have the status of a regiment of dragoons the senior armoured regiment', 'ector and editor one nine three five yusuf bey joseph stephens american activist and businessman two ', 'few more years including the release of the ev seven z chip ev seven nine and ev eight are both cance', 'ngs and misconceptions of scholars two zero zero years ago these ideas have been superseded by later ', 'cult when using an ethnic language like english to some extent there are also shared traditions in th', 'an original group of six european countries this treaty has since expired its functions taken up by s', 'the ground improperly disposed of toxic chemicals and discarded outdated explosives and weapons in co', ' using less lengthy but still thorough articles sometimes called the one nine one one encyclop dia br', 'e opposed by benjamin franklin s one fluid theory later in the century charles augustin de coulomb de', ' indigenous cultures it is quite a usual trope of the english language to describe as erosion the gra', 'ch formulated his characteristic and original synthetist idiom as seen in melancholy in which colour ', ' meridian the sailor is considered to be an emerald shellback see also thermal equator lines of latit', 'e french revolution the latter made burke one of the leading figures within the conservative faction ', 'iii s elder sister which led to mary i queen of scots the alternative line descended from henry viii ', 'ulties promoting itself as a nationwide gasoline marketer competing against truly national brands suc', ' ceannt s four th battalion took the workhouse known as the south dublin union to the southwest membe', 'ritish hit i don t want to go to chelsea and lipstick vogue a tour of the us and canada also saw the ', 'flaws generally users of this method advise avoiding products which lack fixes for known security fla', 'between israel and egypt would not benefit middle east peace but none of the leaders involved were pa']\n",
      "[' a']\n",
      "['an']\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "num_unrollings=100\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, num_unrollings):\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._num_unrollings = num_unrollings\n",
    "    segment = self._text_size // (2*batch_size)\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "    self._last_batch = self._next_batch()\n",
    "  \n",
    "  def _next_batch(self):\n",
    "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "    \n",
    "    # Generate a batch taking only one char from each segment. Next batch will take the\n",
    "    # following char in each segment and so on.\n",
    "    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "    for b in range(self._batch_size):\n",
    "      # use the char id to set the corresponding position in the row to 1\n",
    "      batch[b, char2id(self._text[self._cursor[b]])] = 1.0 \n",
    "      # increment segment cursor +1 so the next batch picks the next char of each segment\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return batch\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    batches = [self._last_batch]\n",
    "    for step in range(self._num_unrollings):\n",
    "      batches.append(self._next_batch())\n",
    "    self._last_batch = batches[-1]\n",
    "    return batches\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "  representation.\"\"\"\n",
    "  \n",
    "  # To reconstruct a word, we need to pick the char in the same position of each batch\n",
    "  # and concatenate them.\n",
    "  # On the first iteration, the comprehension simply transforms ids into chars and \n",
    "  # copies them into s. On every subsequent iteration the comprehension will concatenate\n",
    "  # what's already in s with what's in the next batch in the same position.\n",
    "  # In this way it reconstruct the words by joining together the chars that were in \n",
    "  # different batches\n",
    "  # We have n batches with m chars on each. This will generate m strings with n chars on each\n",
    "  s = [''] * batches[0].shape[0]\n",
    "  for b in batches:\n",
    "    \n",
    "    s = [''.join(x) for x in zip(s, characters(b))]\n",
    "  return s\n",
    "\n",
    "train_batches = BatchGenerator(train_text, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_text, 1, 1)\n",
    "\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(valid_batches.next()))\n",
    "print(batches2string(valid_batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "  \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "  predictions[predictions < 1e-10] = 1e-10\n",
    "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "  \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "  probabilities.\n",
    "  \"\"\"\n",
    "  r = random.uniform(0, 1)\n",
    "  s = 0\n",
    "  for i in range(len(distribution)):\n",
    "    s += distribution[i]\n",
    "    if s >= r:\n",
    "      return i\n",
    "  return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "  \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "  p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "  p[0, sample_distribution(prediction[0])] = 1.0\n",
    "  return p\n",
    "\n",
    "def random_distribution():\n",
    "  \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "  return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_nodes = 128\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "  \n",
    "  # Parameters:\n",
    "  x = dict()\n",
    "  m = dict()\n",
    "  bl = dict()\n",
    "  # Layer 1\n",
    "  x[\"layer 1\"] = tf.Variable(tf.truncated_normal([vocabulary_size, 4*num_nodes], -0.1, 0.1))\n",
    "  m[\"layer 1\"] = tf.Variable(tf.truncated_normal([num_nodes, 4*num_nodes], -0.1, 0.1))\n",
    "  bl[\"layer 1\"] = tf.Variable(tf.zeros([1, 4*num_nodes]))\n",
    "  # Layer 2\n",
    "  x[\"layer 2\"] = tf.Variable(tf.truncated_normal([num_nodes, 4*num_nodes], -0.1, 0.1))\n",
    "  m[\"layer 2\"] = tf.Variable(tf.truncated_normal([num_nodes, 4*num_nodes], -0.1, 0.1))\n",
    "  bl[\"layer 2\"] = tf.Variable(tf.zeros([1, 4*num_nodes]))\n",
    "  \n",
    "  # Variables saving state across unrollings for each layer.\n",
    "  saved_output = dict()\n",
    "  saved_state = dict()\n",
    "  # Layer 1\n",
    "  saved_output[\"layer 1\"] = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state[\"layer 1\"] = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  # Layer 2\n",
    "  saved_output[\"layer 2\"] = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state[\"layer 2\"] = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  \n",
    "  \n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state, layer):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    \n",
    "    lstm_tensor = tf.matmul(i, x[layer]) + tf.matmul(o, m[layer]) + bl[layer]\n",
    "    \n",
    "    input_gate = tf.sigmoid(lstm_tensor[:, :num_nodes])\n",
    "    forget_gate = tf.sigmoid(lstm_tensor[:, num_nodes:2*num_nodes])\n",
    "    update = lstm_tensor[:, 2*num_nodes:3*num_nodes]\n",
    "    output_gate = tf.sigmoid(lstm_tensor[:, 3*num_nodes:])\n",
    "    \n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    return output_gate * tf.tanh(state), state\n",
    "\n",
    "  \n",
    "  # Input data.\n",
    "  train_data = list()\n",
    "  for _ in range(num_unrollings + 1):\n",
    "    train_data.append(\n",
    "      tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
    "  train_inputs = train_data[:num_unrollings]\n",
    "  train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "    \n",
    "  # Unrolled LSTM loop.\n",
    "  outputs = list()\n",
    "  output = saved_output[\"layer 1\"]\n",
    "  state = saved_state[\"layer 1\"]\n",
    "  output_layer_2 = saved_output[\"layer 2\"]\n",
    "  state_layer_2 = saved_state[\"layer 2\"]\n",
    "    \n",
    "  for i in train_inputs:\n",
    "    output, state = lstm_cell(i, output, state, \"layer 1\")\n",
    "    #outputs.append(tf.nn.dropout(output, keep_prob=0.8))\n",
    "    output_layer_2, state_layer_2 = lstm_cell(tf.nn.dropout(output, keep_prob=0.9), \n",
    "                                              output_layer_2, state_layer_2, \"layer 2\")\n",
    "    outputs.append(tf.nn.dropout(output_layer_2, keep_prob=0.9))\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output[\"layer 1\"].assign(output),\n",
    "                                saved_state[\"layer 1\"].assign(state),\n",
    "                                saved_output[\"layer 2\"].assign(output_layer_2),\n",
    "                                saved_state[\"layer 2\"].assign(state_layer_2)]):\n",
    "    \n",
    "    \n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.concat(train_labels, 0), logits=logits))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 5000, 0.1, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  # Sampling and validation eval: batch 1, no unrolling.\n",
    "  sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "  saved_sample_output = dict()  \n",
    "  saved_sample_state = dict()\n",
    "  saved_sample_output[\"layer 1\"] = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state[\"layer 1\"] = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_output[\"layer 2\"] = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state[\"layer 2\"] = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  reset_sample_state = tf.group(\n",
    "    saved_sample_output[\"layer 1\"].assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state[\"layer 1\"].assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_output[\"layer 2\"].assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state[\"layer 2\"].assign(tf.zeros([1, num_nodes])))\n",
    "\n",
    "  sample_output = dict()\n",
    "  sample_state = dict()\n",
    "  sample_output[\"layer 1\"], sample_state[\"layer 1\"] = lstm_cell(\n",
    "    sample_input, saved_sample_output[\"layer 1\"], saved_sample_state[\"layer 1\"], \"layer 1\")\n",
    "    \n",
    "  sample_output[\"layer 2\"], sample_state[\"layer 2\"] = lstm_cell(\n",
    "    sample_output[\"layer 1\"], saved_sample_output[\"layer 2\"], saved_sample_state[\"layer 2\"], \"layer 2\")\n",
    "\n",
    "  with tf.control_dependencies([saved_sample_output[\"layer 1\"].assign(sample_output[\"layer 1\"]),\n",
    "                                saved_sample_state[\"layer 1\"].assign(sample_state[\"layer 1\"]),\n",
    "                                saved_sample_output[\"layer 2\"].assign(sample_output[\"layer 2\"]),\n",
    "                                saved_sample_state[\"layer 2\"].assign(sample_state[\"layer 2\"])]):\n",
    "        \n",
    "    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output[\"layer 2\"], w, b))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 3.304554 learning rate: 10.000000\n",
      "Minibatch perplexity: 27.24\n",
      "================================================================================\n",
      "wdhceaemgsviweqsntkmifnzch poyhcclrhktactlpfeoyoujczartnpyjamzzymqgionzdyjtrprhf\n",
      "jeczt b wzfgaklkvrdqvkekl sgingneddgiqe  ryavbljvlpqobartdyjxzbkonqnpqqoofsypznk\n",
      "zxpwjqus mtoffhyfnlznvlwwjnwvlkcfjvhurfopskjm titlliqgnoeewwfksj uczoxqrayxwxyoj\n",
      "pqlkzwlxnjpyifrjjwnp scfwdmklbyryxzvtcspchyxvseyglllixyqjfodbmydtnjmehimeiftpb j\n",
      "surauhqnfdtvixwdrbqqwzrvulzryxcmelkpstwebqujwnkbdbrzhx seiodwdgovfepryndrkdzldxj\n",
      "================================================================================\n",
      "Validation set perplexity: 27.39\n",
      "Average loss at step 100: 2.922783 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.41\n",
      "Validation set perplexity: 16.03\n",
      "Average loss at step 200: 2.711830 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.27\n",
      "Validation set perplexity: 13.96\n",
      "Average loss at step 300: 2.489787 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.86\n",
      "Validation set perplexity: 10.56\n",
      "Average loss at step 400: 2.344618 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.27\n",
      "Validation set perplexity: 9.76\n",
      "Average loss at step 500: 2.254703 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.21\n",
      "Validation set perplexity: 8.84\n",
      "Average loss at step 600: 2.176030 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.41\n",
      "Validation set perplexity: 8.24\n",
      "Average loss at step 700: 2.107297 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.65\n",
      "Validation set perplexity: 7.86\n",
      "Average loss at step 800: 2.054631 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.48\n",
      "Validation set perplexity: 7.25\n",
      "Average loss at step 900: 2.007206 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.26\n",
      "Validation set perplexity: 7.09\n",
      "Average loss at step 1000: 1.982621 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.64\n",
      "================================================================================\n",
      "xrects in the curledisi colofistucsed fornds s asiestimgrad wortision as nite ca\n",
      "thmitions as deconathor is clitantuuncathicgationilalian visorgebes seacs exy co\n",
      "xorg of the norder of the louthy dacietes if the ulp frinetitic fromcties reporn\n",
      "caanding one fourcfuronosions aliased cellod hif firss of dimdiven exatie whard \n",
      "xteraledisy is a recwratiom thay cargions and is in the aditer assaigip esproc d\n",
      "================================================================================\n",
      "Validation set perplexity: 6.72\n",
      "Average loss at step 1100: 1.972695 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "Validation set perplexity: 6.61\n",
      "Average loss at step 1200: 1.917569 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.94\n",
      "Validation set perplexity: 6.25\n",
      "Average loss at step 1300: 1.891506 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.55\n",
      "Validation set perplexity: 6.09\n",
      "Average loss at step 1400: 1.879796 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.55\n",
      "Validation set perplexity: 5.83\n",
      "Average loss at step 1500: 1.844570 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.11\n",
      "Validation set perplexity: 5.78\n",
      "Average loss at step 1600: 1.817092 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.56\n",
      "Validation set perplexity: 5.50\n",
      "Average loss at step 1700: 1.823112 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.92\n",
      "Validation set perplexity: 5.30\n",
      "Average loss at step 1800: 1.780754 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.98\n",
      "Validation set perplexity: 5.14\n",
      "Average loss at step 1900: 1.767162 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.93\n",
      "Validation set perplexity: 5.06\n",
      "Average loss at step 2000: 1.761185 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.77\n",
      "================================================================================\n",
      "h is than ilber lathrusching of mosificzer electramentaia merpor on golt instret\n",
      "gratij s lorht to its obtitions original sdickus and stopment is whitely it in r\n",
      "xsts enaly nine is them way ctory a prag commer it a duy in brot exectoractics t\n",
      "twerb green of the centrainer hear sinces to forgies and agailh depgin has be bu\n",
      "x brantic ocm by fair terme amon is cathers a soloricm propan bhorogistire by re\n",
      "================================================================================\n",
      "Validation set perplexity: 4.96\n",
      "Average loss at step 2100: 1.743151 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.84\n",
      "Validation set perplexity: 4.93\n",
      "Average loss at step 2200: 1.725098 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.65\n",
      "Validation set perplexity: 4.73\n",
      "Average loss at step 2300: 1.698655 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.51\n",
      "Validation set perplexity: 4.67\n",
      "Average loss at step 2400: 1.674914 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.25\n",
      "Validation set perplexity: 4.59\n",
      "Average loss at step 2500: 1.669203 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.25\n",
      "Validation set perplexity: 4.54\n",
      "Average loss at step 2600: 1.651002 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.34\n",
      "Validation set perplexity: 4.41\n",
      "Average loss at step 2700: 1.628523 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.02\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 2800: 1.605445 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.07\n",
      "Validation set perplexity: 4.19\n",
      "Average loss at step 2900: 1.610385 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.90\n",
      "Validation set perplexity: 4.17\n",
      "Average loss at step 3000: 1.596744 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.09\n",
      "================================================================================\n",
      "ver charshey child be ine hm on in south meck and dony four three one nine four \n",
      "fored to alabm and atmm and jew costa not an organien condicimed the ghowers mic\n",
      "qualey rich wantial with hetroogh geen type beoge was resugation properser new d\n",
      "trass im the carding game s fol bruzabn write a sitio s more resident jifreed ne\n",
      "grapterum ol the well as pnoke the day deatm  of that distules names circuel mus\n",
      "================================================================================\n",
      "Validation set perplexity: 4.18\n",
      "Average loss at step 3100: 1.582923 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.02\n",
      "Validation set perplexity: 4.05\n",
      "Average loss at step 3200: 1.587034 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.98\n",
      "Validation set perplexity: 4.06\n",
      "Average loss at step 3300: 1.583204 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.95\n",
      "Validation set perplexity: 4.07\n",
      "Average loss at step 3400: 1.577752 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.75\n",
      "Validation set perplexity: 4.00\n",
      "Average loss at step 3500: 1.573246 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.72\n",
      "Validation set perplexity: 4.05\n",
      "Average loss at step 3600: 1.556869 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.65\n",
      "Validation set perplexity: 4.06\n",
      "Average loss at step 3700: 1.551182 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.80\n",
      "Validation set perplexity: 3.98\n",
      "Average loss at step 3800: 1.552806 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.71\n",
      "Validation set perplexity: 3.97\n",
      "Average loss at step 3900: 1.535348 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.98\n",
      "Average loss at step 4000: 1.523481 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.65\n",
      "================================================================================\n",
      "e long born fractors repiorsto into the second constitutionally tcruce affairs o\n",
      "ine aggenrative g qule from servey in applies in ontounds a matol writing misles\n",
      "lade french actually the arabe the other bogys of the fecmines in african but be\n",
      "x of bera were no southard century windressive was newspanda nequivations categ \n",
      "wandwandar s est iskay hapare aviolections in at the life this brees home valie \n",
      "================================================================================\n",
      "Validation set perplexity: 3.97\n",
      "Average loss at step 4100: 1.527870 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.91\n",
      "Average loss at step 4200: 1.522961 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.95\n",
      "Average loss at step 4300: 1.532592 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.92\n",
      "Average loss at step 4400: 1.533881 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.62\n",
      "Validation set perplexity: 3.95\n",
      "Average loss at step 4500: 1.526958 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.57\n",
      "Validation set perplexity: 3.83\n",
      "Average loss at step 4600: 1.512831 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 3.87\n",
      "Average loss at step 4700: 1.512359 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.79\n",
      "Average loss at step 4800: 1.508838 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.67\n",
      "Validation set perplexity: 3.84\n",
      "Average loss at step 4900: 1.498910 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.79\n",
      "Average loss at step 5000: 1.480399 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.46\n",
      "================================================================================\n",
      " is either the based the mengemer eventually coales in hinhrote many to five two\n",
      "xaciter part of a zetu scottering was chicces s two zero zero developed systems \n",
      "mers law mifor dung for progresstress dyacemas vaises tectionity of first friend\n",
      "m up caligalis to the important perfice ample of the function reaches from one o\n",
      "werl and computer the a includer the blue and the equapismseverman french and de\n",
      "================================================================================\n",
      "Validation set perplexity: 3.81\n",
      "Average loss at step 5100: 1.482542 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 3.76\n",
      "Average loss at step 5200: 1.495296 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.77\n",
      "Average loss at step 5300: 1.497002 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 3.75\n",
      "Average loss at step 5400: 1.511653 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.69\n",
      "Validation set perplexity: 3.74\n",
      "Average loss at step 5500: 1.490686 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.50\n",
      "Validation set perplexity: 3.72\n",
      "Average loss at step 5600: 1.490145 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 5700: 1.486263 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 5800: 1.488758 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 5900: 1.481013 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 6000: 1.504511 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.84\n",
      "================================================================================\n",
      "k singan easter care satspice where it of aristrent ejemb of navalus drch their \n",
      "jer if dominant s during polently list a commonity that the radis canants that t\n",
      "dedows plasers of second rablingly drakian one three three one nine four zero on\n",
      "chrication in lrs from the emergency reachine the horaiding perceived only of th\n",
      "an dawaltographical played both geography  antex was under the first i pure plar\n",
      "================================================================================\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 6100: 1.532652 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 6200: 1.498066 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 6300: 1.485782 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 6400: 1.495139 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 6500: 1.492404 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 6600: 1.487829 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.57\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 6700: 1.519744 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 6800: 1.501804 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.56\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 6900: 1.499744 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.64\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 7000: 1.515078 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.53\n",
      "================================================================================\n",
      "use of island information althought be amount king and culsin resistons esqyonis\n",
      "honomail degree to be an angul begites central creedichman moleculas a comweles \n",
      "ana whiteright edacccleot of than the central seven one nine eight attacking smi\n",
      "er or accted in a novel to destroy different two at such define a the criticisat\n",
      "x result oven yero and them as the prudically eye she stitling as a physically d\n",
      "================================================================================\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 7100: 1.516009 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 7200: 1.516526 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 7300: 1.500565 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 7400: 1.484329 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 7500: 1.494850 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 7600: 1.483746 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 7700: 1.467838 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 7800: 1.459373 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 7900: 1.473922 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 8000: 1.473856 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.47\n",
      "================================================================================\n",
      "jor romit which vicwain by industers and was they been traff parliqual quirking \n",
      "s sufficient in ballar caellz laune to weles of a oslangraphy ruing fartherderic\n",
      "ologyman living ford the integer mainta one nine seven the arvically overwardem \n",
      "x bords becime in the most minister outrown teams were well ega others but numbe\n",
      "ell from wwxes tephie were mainer to m polster s effective from the lodge averag\n",
      "================================================================================\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 8100: 1.469107 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 8200: 1.476866 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 8300: 1.480719 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 8400: 1.485310 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 8500: 1.488199 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 8600: 1.477253 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 8700: 1.471551 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 8800: 1.483639 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 8900: 1.471585 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 9000: 1.461120 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.41\n",
      "================================================================================\n",
      "ter in called the complech of the consists of whike corcorarists however the win\n",
      "ught s transing where a billoge years lennor broz forstaftanes precised and aust\n",
      "lls and certain is separonals there hempould bo seems the formated on the treaty\n",
      "created by the loed at also one two eight seven each memo translation in the sho\n",
      "s the kevenqeple one nine nine five three nine gey aslase name of golds this sis\n",
      "================================================================================\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 9100: 1.470818 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 9200: 1.471506 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 9300: 1.487332 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 9400: 1.490798 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 9500: 1.486429 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 9600: 1.476158 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 9700: 1.479398 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 9800: 1.478012 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 9900: 1.471316 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 10000: 1.457849 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.31\n",
      "================================================================================\n",
      "x of the who meraminatf one eight eight zero should i with down ark m defense on\n",
      "e and book to causelate onlines in saving to employing community connective arte\n",
      "g excepted was newerwas forces oppost of the resort about one india sannates met\n",
      "an two from one nine nine eight two notaries of the informations of his team pan\n",
      "an acc morts such as a manoguetopy institute was law rade used for faloher cowni\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10100: 1.465811 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10200: 1.478082 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10300: 1.479807 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10400: 1.492309 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10500: 1.475162 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10600: 1.476264 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10700: 1.473380 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10800: 1.475507 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 10900: 1.469661 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 11000: 1.492616 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.76\n",
      "================================================================================\n",
      "prison on the god ghow mi meexzinaw see also mainterblerf gry now the learnet du\n",
      "xs august has a company the still copariau like human versions oscraved and coal\n",
      "oossis then that recently one two zerodoe resources makel ua lap with takes in t\n",
      "ove is project complainated in the own solo measurest long cyp music ustar possi\n",
      "k herit zero seven eight six six eniccessic refice majas deportail of cimily ter\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 11100: 1.522151 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 11200: 1.486097 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 11300: 1.473729 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 11400: 1.485197 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 11500: 1.484892 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 11600: 1.479177 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 11700: 1.509727 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 11800: 1.490750 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.56\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 11900: 1.491562 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12000: 1.507981 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.53\n",
      "================================================================================\n",
      "que the rish grap micemynez one nine nine three four by the same were compine de\n",
      "um and or outpay to be cress been atthens three an are three nine that treitimet\n",
      "h one nine six zero sea mast webseff directed by book nohal regional the largest\n",
      "t home and excelved vik after ce party color the moble portugually record or aft\n",
      "z of they cedter one one seven two chazs on the spals greek bultarian line seaza\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12100: 1.508814 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 12200: 1.509276 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 12300: 1.492685 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12400: 1.477121 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12500: 1.488400 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12600: 1.476126 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12700: 1.459489 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12800: 1.453551 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 12900: 1.468848 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 13000: 1.467878 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.41\n",
      "================================================================================\n",
      "jer such as to meetarians addition public to mevologism is also college on a fig\n",
      "mers review that one of comprainn s duven antisqeroutely whis mentit colornation\n",
      "xle on use to oftic in a pilite sby no imguttmy bases as fellows of the story in\n",
      "que and the conservative placed with a aulstic presamment newer luses for a comm\n",
      "jess himself articles include part confirred and the diring rose regards ineviat\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13100: 1.463989 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13200: 1.471877 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13300: 1.476276 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13400: 1.481340 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13500: 1.483048 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13600: 1.473568 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 13700: 1.469668 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 13800: 1.479228 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13900: 1.466724 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 14000: 1.457451 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.38\n",
      "================================================================================\n",
      "jection words one nine nine five six two jlum to bir s three one killed do nazic\n",
      "pression of modern de traditional fishs into the vreukling minu n villagues for \n",
      "gan trideboddon expsostes onle dust drived barpwere the good references these pe\n",
      "hard to many is along that stly the time as parlett of sox press the cleties the\n",
      "graf features bale or a f the carrenta the world same rejested that other assind\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n"
     ]
    }
   ],
   "source": [
    "num_steps = 14001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  mean_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batches = train_batches.next()\n",
    "    feed_dict = dict()\n",
    "    for i in range(num_unrollings + 1):\n",
    "      feed_dict[train_data[i]] = batches[i]\n",
    "    _, l, predictions, lr = session.run(\n",
    "      [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    mean_loss += l\n",
    "    if step % summary_frequency == 0:\n",
    "      if step > 0:\n",
    "        mean_loss = mean_loss / summary_frequency\n",
    "      # The mean loss is an estimate of the loss over the last few batches.\n",
    "      print(\n",
    "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "      mean_loss = 0\n",
    "      labels = np.concatenate(list(batches)[1:])\n",
    "      print('Minibatch perplexity: %.2f' % float(\n",
    "        np.exp(logprob(predictions, labels))))\n",
    "      if step % (summary_frequency * 10) == 0:\n",
    "        # Generate some samples.\n",
    "        print('=' * 80)\n",
    "        for _ in range(5):\n",
    "          feed = sample(random_distribution())\n",
    "          sentence = characters(feed)[0]\n",
    "          reset_sample_state.run()\n",
    "          for _ in range(79):\n",
    "            prediction = sample_prediction.eval({sample_input: feed})\n",
    "            feed = sample(prediction)\n",
    "            sentence += characters(feed)[0]\n",
    "          print(sentence)\n",
    "        print('=' * 80)\n",
    "      # Measure validation set perplexity.\n",
    "      reset_sample_state.run()\n",
    "      valid_logprob = 0\n",
    "      for _ in range(valid_size):\n",
    "        b = valid_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "      print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "        valid_logprob / valid_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
